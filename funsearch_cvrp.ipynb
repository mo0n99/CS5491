{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ba1915fced4e72",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Run FunSearch on Capacitated Vehicle Routing Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e93216-c6da-4283-bd87-19d2c927ea01",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "Our project is to apply [FunSearch](https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/) on [Capacitated Vehicle Routing Problem](https://developers.google.com/optimization/routing/cvrp)(CVRP) to find better heuristic algorithm.\n",
    "\n",
    "Instead of relying on human intuitions or manual trial-and-errors to find a better heuristic, **FunSearch**  automate the design process by treating it as a search problem.\n",
    "\n",
    "FunSearch refers to a heuristic function as a program. FunSearch first asks an LLM to create a set \n",
    "of programs, each of which will be incorporated into the general heuristic code templatve. Each program will be evaluated on some test instancms \n",
    "and the resulting performance will be recorded. Then, the main loop of FunSearch starts, where n \n",
    "each iteration, FunSearch picks a promising pronce) from the setof \n",
    "programs created before. This program will be sent to an LLM for further modifications so thatthe \n",
    "performance can be improved. Then, the modified program is evaroblem), and it will replace the original program f its \n",
    "performance improves. This process will repeat for many iterations until a novel program is otained \n",
    "or some pre-defined max # of iterations is\n",
    "\n",
    "This project is divided into 5 steps:\n",
    "1. Implement 'LLM' interface.\n",
    "2. Implement a 'SandBox' interface.\n",
    "3. Prepare a 'specification'.\n",
    "4. Prepare a dataset.\n",
    "5. Start FunSearch.\n",
    "\n",
    "**Caution**\n",
    "\n",
    "This document references https://github.com/RayZhhh/funsearchFunSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d02b8e9c3ba67",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Preparation: download the project file from github. And update system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22453e8153e0934c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/RayZhhh/funsearch.git\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/content/funsearch/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47175708cc0a93",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. Implement LLM interface\n",
    "Set the API's IP address according to your API provider (See line 65 in the following code).\n",
    "```python\n",
    "conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
    "```\n",
    "You should prepare a 'key' for the LLM API. And fill them in the header (See line 76-80 in the following code).\n",
    "```python\n",
    "headers = {\n",
    "    'Authorization': 'Bearer [put your key here, the key may start with \"sk-...\"]',\n",
    "    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "```\n",
    "**Caution**\n",
    "The LLM interface implementation references https://github.com/RayZhhh/funsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999e45c9a568b08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import multiprocessing\n",
    "from typing import Collection, Any\n",
    "import http.client\n",
    "from implementation import sampler\n",
    "\n",
    "\n",
    "def _trim_preface_of_body(sample: str) -> str:\n",
    "    \"\"\"Trim the redundant descriptions/symbols/'def' declaration before the function body.\n",
    "    Please see my comments in sampler.LLM (in sampler.py).\n",
    "    Since the LLM used in this file is not a pure code completion LLM, this trim function is required.\n",
    "\n",
    "    -Example sample (function & description generated by LLM):\n",
    "    -------------------------------------\n",
    "    This is the optimized function ...\n",
    "    def priority_v2(...) -> ...:\n",
    "        return ...\n",
    "    This function aims to ...\n",
    "    -------------------------------------\n",
    "    -This function removes the description above the function's signature, and the function's signature.\n",
    "    -The indent of the code is preserved.\n",
    "    -Return of this function:\n",
    "    -------------------------------------\n",
    "        return ...\n",
    "    This function aims to ...\n",
    "    -------------------------------------\n",
    "    \"\"\"\n",
    "    lines = sample.splitlines()\n",
    "    func_body_lineno = 0\n",
    "    find_def_declaration = False\n",
    "    for lineno, line in enumerate(lines):\n",
    "        # find the first 'def' statement in the given code\n",
    "        if line[:3] == 'def':\n",
    "            func_body_lineno = lineno\n",
    "            find_def_declaration = True\n",
    "            break\n",
    "    if find_def_declaration:\n",
    "        code = ''\n",
    "        for line in lines[func_body_lineno + 1:]:\n",
    "            code += line + '\\n'\n",
    "        return code\n",
    "    return sample\n",
    "\n",
    "\n",
    "class LLMAPI(sampler.LLM):\n",
    "    \"\"\"Language model that predicts continuation of provided source code.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples_per_prompt: int, trim=True):\n",
    "        super().__init__(samples_per_prompt)\n",
    "        additional_prompt = ('You are an expert in optimization of CVRP, generate a specific improvement strategy based on the current state of the solution.'\n",
    "                             'Complete a different and more complex Python function. '\n",
    "                             'Be creative and you can insert multiple if-else and for-loop in the code logic.'\n",
    "                             'Only output the Python code, no descriptions.')\n",
    "        self._additional_prompt = additional_prompt\n",
    "        self._trim = trim\n",
    "\n",
    "    def draw_samples(self, prompt: str) -> Collection[str]:\n",
    "        \"\"\"Returns multiple predicted continuations of `prompt`.\"\"\"\n",
    "        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]\n",
    "\n",
    "    def _draw_sample(self, content: str) -> str:\n",
    "        prompt = '\\n'.join([content, self._additional_prompt])\n",
    "        while True:\n",
    "            try:\n",
    "                conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
    "                payload = json.dumps({\n",
    "                    \"max_tokens\": 512,\n",
    "                    \"model\": \"gpt-3.5-turbo\",\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "                headers = {\n",
    "                    'Authorization': 'Bearer sk-5szlvRHdRzZvQfum20165bFa0364427bA0B08cAf8765D52e',\n",
    "                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
    "                    'Content-Type': 'application/json'\n",
    "                }\n",
    "                conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
    "                res = conn.getresponse()\n",
    "                data = res.read().decode(\"utf-8\")\n",
    "                data = json.loads(data)\n",
    "                response = data['choices'][0]['message']['content']\n",
    "                # trim function\n",
    "                if self._trim:\n",
    "                    response = _trim_preface_of_body(response)\n",
    "                return response\n",
    "            except Exception:\n",
    "                time.sleep(2)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27817cdec2cedfc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. Implement a 'SandBox' interface\n",
    "**Caution**:\n",
    "The Sandbox interface implementation references https://github.com/RayZhhh/funsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d88a87535b6b2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from implementation import evaluator\n",
    "from implementation import evaluator_accelerate\n",
    "\n",
    "\n",
    "class Sandbox(evaluator.Sandbox):\n",
    "    \"\"\"Sandbox for executing generated code. Implemented by RZ.\n",
    "\n",
    "    RZ: Sandbox returns the 'score' of the program and:\n",
    "    1) avoids the generated code to be harmful (accessing the internet, take up too much RAM).\n",
    "    2) stops the execution of the code in time (avoid endless loop).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=False, numba_accelerate=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            verbose         : Print evaluate information.\n",
    "            numba_accelerate: Use numba to accelerate the evaluation. It should be noted that not all numpy functions\n",
    "                              support numba acceleration, such as np.piecewise().\n",
    "        \"\"\"\n",
    "        self._verbose = verbose\n",
    "        self._numba_accelerate = numba_accelerate\n",
    "\n",
    "    def run(\n",
    "            self,\n",
    "            program: str,\n",
    "            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')\n",
    "            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.\n",
    "            inputs: Any,  # refers to the dataset\n",
    "            test_input: str,  # refers to the current instance\n",
    "            timeout_seconds: int,\n",
    "            **kwargs  # RZ: add this\n",
    "    ) -> tuple[Any, bool]:\n",
    "        \"\"\"Returns `function_to_run(test_input)` and whether execution succeeded.\n",
    "\n",
    "        RZ: If the generated code (generated by LLM) is executed successfully,\n",
    "        the output of this function is the score of a given program.\n",
    "        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.\n",
    "        \"\"\"\n",
    "        dataset = inputs[test_input]\n",
    "        try:\n",
    "            result_queue = multiprocessing.Queue()\n",
    "            process = multiprocessing.Process(\n",
    "                target=self._compile_and_run_function,\n",
    "                args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)\n",
    "            )\n",
    "            process.start()\n",
    "            process.join(timeout=timeout_seconds)\n",
    "            if process.is_alive():\n",
    "                # if the process is not finished in time, we consider the program illegal\n",
    "                process.terminate()\n",
    "                process.join()\n",
    "                results = None, False\n",
    "            else:\n",
    "                if not result_queue.empty():\n",
    "                    results = result_queue.get_nowait()\n",
    "                else:\n",
    "                    results = None, False\n",
    "\n",
    "            return results\n",
    "        except:\n",
    "            return None, False\n",
    "\n",
    "    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,\n",
    "                                  result_queue):\n",
    "        try:\n",
    "            # optimize the code (decorate function_to_run with @numba.jit())\n",
    "            if numba_accelerate:\n",
    "                program = evaluator_accelerate.add_numba_decorator(\n",
    "                    program=program,\n",
    "                    function_to_evolve=function_to_evolve\n",
    "                )\n",
    "            # compile the program, and maps the global func/var/class name to its address\n",
    "            all_globals_namespace = {}\n",
    "            # execute the program, map func/var/class to global namespace\n",
    "            exec(program, all_globals_namespace)\n",
    "            # get the pointer of 'function_to_run'\n",
    "            function_to_run = all_globals_namespace[function_to_run]\n",
    "            # return the execution results\n",
    "            results = function_to_run(dataset)\n",
    "            # the results must be int or float\n",
    "            if not isinstance(results, (int, float)):\n",
    "                result_queue.put((None, False))\n",
    "                return\n",
    "            result_queue.put((results, True))\n",
    "        except Exception:\n",
    "            # if raise any exception, we assume the execution failed\n",
    "            result_queue.put((None, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a05827354f9ae",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. Prepare a 'specification'\n",
    "This code implements solution to the classic CVRP, which involves:\n",
    "1. Initializes all vehicles at the depot (node 0)\n",
    "2. For each vehicle:\n",
    "   - Selects next node using demand-aware priority scores\n",
    "   - Updates route until capacity is reached\n",
    "   - Returns to depot to finalize route\n",
    "4. Repeats until all customer demands served\n",
    "5. Evaluates total travel cost across all routes\n",
    "\n",
    "This code includes 3 components:\n",
    "1. `vehicle_routing`\n",
    "    - Constructs routes sequentially using a greedy insertion stratege\n",
    "    - Dynamically adjusts available nodes using\n",
    "        - Capacity checks: Verifies if next node's demand can be fulfilled\n",
    "\t- Exclusion logic: Prevents node revisits via masking\n",
    "    - Automatically dispatches new vehicles when capacity is exhausted\n",
    "2. `priority`\n",
    "    - Implements a weighted distance metric that considers:\n",
    "\t- Base travel cost (distance from current position)\n",
    "\t- Demand-adjusted scoring (demand used as penalty/reward)\n",
    "    - Favors nodes where:\n",
    "\t- Distance is short (minimizes travel time)\n",
    "\t- Demand fits remaining capacity (maximizes utilization)\n",
    "3. `evaluate`\n",
    "    - Computes average performance across mus negative cost convention for compatibility with maximmizations all routesroutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f875d128a693a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "specification = r'''\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def vehicle_routing(vehicle_capacity: int, node_requirements: np.ndarray, \n",
    "           distance_matrix: np.ndarray) -> tuple[list, float]:\n",
    "    \"\"\"\n",
    "    Solves the Capacitated Vehicle Routing Problem (CVRP) using a heuristic approach.\n",
    "    \n",
    "    Args:\n",
    "        vehicle_capacity: Maximum load capacity of each vehicle\n",
    "        node_requirements: Array of demand values for each node (index 0 is depot)\n",
    "        distance_matrix: Square matrix of inter-node travel distances\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (list of routes, total travel distance)\n",
    "        - routes: List of routes where each sublist represents a vehicle's path\n",
    "        - total_distance: Sum of all route distances including depot returns\n",
    "    \n",
    "    Algorithm:\n",
    "        1. Initializes vehicles at depot (node 0)\n",
    "        2. Sequentially builds routes using demand-aware priority scoring\n",
    "        3. Manages vehicle reloading when capacity is exhausted\n",
    "        4. Ensures no repeated node visits through matrix manipulation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Routing state initialization\n",
    "    current_route = [] # Active vehicle's path\n",
    "    completed_routes = [] # Finished vehicle paths\n",
    "    total_distance = 0 # Cumulative distance across all routes\n",
    "    current_leg_distance = 0 # Distance for current vehicle's route\n",
    "    current_load = 0 # Current vehicle's carried load\n",
    "    current_location = 0 # Always starts at depot (node 0)\n",
    "    visited_count = 0  # Tracks fulfilled demand points\n",
    "    \n",
    "    # Matrix preparation\n",
    "    working_matrix = distance_matrix.copy()\n",
    "    depot_return_costs = working_matrix[:, 0].copy()\n",
    "    np.fill_diagonal(working_matrix, 1e10) # Block self-loops\n",
    "    working_matrix[:, 0] = 1e10  # Prevent depot returns\n",
    "    \n",
    "    def select_next_node(scores: np.ndarray, excluded_nodes: list) -> int:\n",
    "        \"\"\"\n",
    "        Internal node selection logic with exclusion management\n",
    "        \n",
    "        Args:\n",
    "            scores: Priority scores for node selection\n",
    "            excluded_nodes: Nodes to exclude from selection\n",
    "            \n",
    "        Returns:\n",
    "            int: Index of selected node\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: When no valid nodes remain\n",
    "        \"\"\"\n",
    "        # Flatten and deduplicate exclusion list\n",
    "        excluded = {n for group in excluded_nodes for n in group}\n",
    "        valid_mask = np.ones_like(scores, dtype=bool)\n",
    "        valid_mask[list(excluded)] = False\n",
    "        \n",
    "        if not np.any(valid_mask):\n",
    "            raise ValueError(\"No available nodes for selection\")\n",
    "        \n",
    "        # Get highest valid score\n",
    "        valid_scores = scores[valid_mask]\n",
    "        max_idx = np.argmax(valid_scores)\n",
    "        return np.where(valid_mask)[0][max_idx]\n",
    "\n",
    "    # Main routing loop\n",
    "    while visited_count < len(node_requirements) - 1:\n",
    "        # Calculate selection priorities\n",
    "        available_capacity = vehicle_capacity - current_load\n",
    "        priority_scores = priority(\n",
    "            current_location,\n",
    "            working_matrix.copy(),\n",
    "            available_capacity,\n",
    "            node_requirements\n",
    "        )\n",
    "        \n",
    "        # Generate exclusion list\n",
    "        exclusion_list = completed_routes + [[current_location] + current_route]\n",
    "        \n",
    "        try:\n",
    "            chosen_node = select_next_node(priority_scores, exclusion_list)\n",
    "        except ValueError:\n",
    "            break  # No more nodes available\n",
    "        \n",
    "        # Validate selection\n",
    "        demand = node_requirements[chosen_node]\n",
    "        valid_selection = (\n",
    "            current_load + demand <= vehicle_capacity \n",
    "            and chosen_node != 0\n",
    "        )\n",
    "        \n",
    "        if valid_selection:\n",
    "            # Update current route\n",
    "            current_leg_distance += working_matrix[current_location, chosen_node]\n",
    "            current_load += demand\n",
    "            current_route.append(chosen_node)\n",
    "            visited_count += 1\n",
    "            \n",
    "            # Block future selections of this node\n",
    "            working_matrix[:, chosen_node] = 1e10\n",
    "            current_location = chosen_node\n",
    "        else:\n",
    "            # Finalize current vehicle's route\n",
    "            current_leg_distance += depot_return_costs[current_location]\n",
    "            total_distance += current_leg_distance\n",
    "            completed_routes.append(current_route)\n",
    "            \n",
    "            # Reset for new vehicle\n",
    "            current_location = 0\n",
    "            current_leg_distance = 0\n",
    "            current_load = 0\n",
    "            current_route = []\n",
    "    \n",
    "    # Handle final vehicle return\n",
    "    if current_location != 0:\n",
    "        current_leg_distance += depot_return_costs[current_location]\n",
    "        total_distance += current_leg_distance\n",
    "        completed_routes.append(current_route)\n",
    "    \n",
    "    return completed_routes, total_distance\n",
    "\n",
    "@funsearch.run\n",
    "def evaluate(test_instances: dict) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates routing performance across multiple problem instances.\n",
    "    \n",
    "    Args:\n",
    "        test_instances: Dictionary of CVRP instances with:\n",
    "            - 'capacity': Vehicle capacity\n",
    "            - 'demand': Node requirements array\n",
    "            - 'edge_weight': Distance matrix\n",
    "            \n",
    "    Returns:\n",
    "        float: Negative average cost (for maximization objectives)\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    for instance in test_instances.values():\n",
    "        _, route_cost = vehicle_routing(\n",
    "            instance['capacity'],\n",
    "            instance['demand'],\n",
    "            instance['edge_weight']\n",
    "        )\n",
    "        costs.append(route_cost)\n",
    "    return -np.mean(costs)\n",
    "\n",
    "@funsearch.evolve\n",
    "def priority(current_node: int, distance_data: np.ndarray,\n",
    "       remaining_capacity: int, node_demands: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates node selection scores balancing distance and demand.\n",
    "    \n",
    "    Args:\n",
    "        current_node: Current vehicle position\n",
    "        distance_data: Modified distance matrix\n",
    "        remaining_capacity: Available vehicle capacity\n",
    "        node_demands: Demand values for all nodes\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Priority scores (higher = better)\n",
    "    \"\"\"\n",
    "    scores = distance_data[current_node].copy()\n",
    "    \n",
    "    for idx, demand in enumerate(node_demands):\n",
    "        adjustment = math.sqrt(demand)\n",
    "        if remaining_capacity >= demand:\n",
    "            scores[idx] -= adjustment  # Favor closer high-demand nodes\n",
    "        else:\n",
    "            # Penalize nodes exceeding capacity\n",
    "            scores[idx] += adjustment if scores[idx] > 0 else -adjustment\n",
    "    \n",
    "    return -scores  # Convert to negative for minimization\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bfe61e1661e18",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. Prepare a dataset\n",
    "Our project use [**CVRPLib**](http://vrp.atd-lab.inf.puc-rio.br/index.php/en/ ) setB for testing.\n",
    "\n",
    "CVRPLib is the go-to benchmark dataset for CVRP, offering standardized instances with known optimal solutions that enable reliable algorithm comparisons. While invaluable for research and education, it focuses mainly on small-to-medium scale, static problems with homogeneous fleets, lacking real-world complexities like dynamic conditions or large-scale scenarios. Though limited for modern logistics applications, it remains essential for validating fundamental routing algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea85ccfc8c0ca6d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'cvrplib/setE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m cvrp_dataset \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      6\u001b[0m cvrp_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dataset_path):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vrp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     10\u001b[0m         instances \u001b[38;5;241m=\u001b[39m vrplib\u001b[38;5;241m.\u001b[39mread_instance(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, file))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'cvrplib/setE'"
     ]
    }
   ],
   "source": [
    "import vrplib\n",
    "import os\n",
    "\n",
    "dataset_path = \"cvrplib/setB\"\n",
    "cvrp_dataset = {}\n",
    "cvrp_dataset['B'] = {}\n",
    "\n",
    "for file in os.listdir(dataset_path):\n",
    "    if file.endswith(\".vrp\"):\n",
    "        instances = vrplib.read_instance(os.path.join(dataset_path, file))\n",
    "        cvrp_dataset['B'][file[:-4]] = instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66651fb2764ce9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5. Start FunSearch\n",
    "Please note that in jupyter notebook the following code will fail. This is because juypter does not support multiprocessing. Colab backend supports multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ec0c796d09ca1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from implementation import funsearch\n",
    "from implementation import config\n",
    "\n",
    "# It should be noted that the if __name__ == '__main__' is required.\n",
    "# Because the inner code uses multiprocess evaluation.\n",
    "if __name__ == '__main__':\n",
    "    class_config = config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)\n",
    "    config = config.Config(samples_per_prompt=4, evaluate_timeout_seconds=30)\n",
    "    global_max_sample_num = 100  # if it is set to None, funsearch will execute an endless loop\n",
    "    funsearch.main(\n",
    "        specification=specification,\n",
    "        inputs=cvrp_dataset,\n",
    "        config=config,\n",
    "        max_sample_nums=global_max_sample_num,\n",
    "        class_config=class_config,\n",
    "        log_dir='../logs/funsearch_llm_api'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
