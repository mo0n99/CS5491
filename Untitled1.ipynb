{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 删除旧的克隆仓库\n",
        "!rm -rf funsearch\n",
        "\n",
        "# 克隆新的仓库\n",
        "!git clone https://github.com/RayZhhh/funsearch.git\n",
        "\n",
        "# 更新系统路径\n",
        "import sys\n",
        "sys.path.append('/content/funsearch')"
      ],
      "metadata": {
        "id": "zPSumpRM-1Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb399a6-88bf-47ff-d916-991322725987"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'funsearch'...\n",
            "remote: Enumerating objects: 189, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 189 (delta 77), reused 156 (delta 44), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (189/189), 235.50 KiB | 11.77 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "repo_path = '/content/funsearch'\n",
        "implementation_path = os.path.join(repo_path, 'implementation')\n",
        "init_file_path = os.path.join(implementation_path, '__init__.py')\n",
        "if not os.path.exists(implementation_path):\n",
        "    print(f\"路径 {implementation_path} 不存在，请检查。\")\n",
        "else:\n",
        "    if not os.path.exists(init_file_path):\n",
        "        open(init_file_path, 'a').close()\n",
        "        print(f\"{init_file_path} 文件已创建。\")\n",
        "    else:\n",
        "        print(f\"{init_file_path} 文件已存在。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuf3ngq85yBX",
        "outputId": "e212c505-1069-4634-830d-60af2589db32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/funsearch/implementation/__init__.py 文件已创建。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/funsearch')\n",
        "\n",
        "try:\n",
        "    from implementation import sampler  # 替换为你想导入的具体模块\n",
        "    print(\"模块导入成功！\")\n",
        "except ImportError as e:\n",
        "    print(f\"模块导入失败：{e}\")"
      ],
      "metadata": {
        "id": "vigGm-XQ2VXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbd6cf8-62af-4de6-c985-d1f3e0dbc4d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模块导入成功！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import http.client\n",
        "import json\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "from typing import Collection, Any, List, Tuple\n",
        "from implementation import sampler\n",
        "\n",
        "# 1. 实现LLM接口\n",
        "class LLMAPI(sampler.LLM):\n",
        "    def __init__(self, samples_per_prompt: int):\n",
        "        super().__init__(samples_per_prompt)\n",
        "        self._additional_prompt = ('Complete a Python function for CVRP heuristic. Include logic for vehicle capacity, '\n",
        "                                   'customer demands and route optimization. Only output the Python code, no descriptions.')\n",
        "\n",
        "    def draw_samples(self, prompt: str) -> Collection[str]:\n",
        "        return [self._draw_sample(prompt) for _ in range(self._samples_per_prompt)]\n",
        "\n",
        "    def _draw_sample(self, content: str) -> str:\n",
        "        while True:\n",
        "            prompt = '\\n'.join([content, self._additional_prompt])\n",
        "            try:\n",
        "                conn = http.client.HTTPSConnection(\"api.chatanywhere.com.cn\")\n",
        "                payload = json.dumps({\n",
        "                    \"model\": \"gpt-3.5-turbo\",\n",
        "                    \"max_tokens\": 512,\n",
        "                    \"messages\": [\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt\n",
        "                        }\n",
        "                    ]\n",
        "                })\n",
        "                headers = {\n",
        "                    'Authorization': 'Bearer sk-5szlvRHdRzZvQfum20165bFa0364427bA0B08cAf8765D52e',\n",
        "                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n",
        "                    'Content-Type': 'application/json'\n",
        "                }\n",
        "                conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
        "                res = conn.getresponse()\n",
        "                data = res.read().decode(\"utf-8\")\n",
        "                data = json.loads(data)\n",
        "                response = data['choices'][0]['message']['content']\n",
        "                return response\n",
        "            except Exception:\n",
        "                continue\n"
      ],
      "metadata": {
        "id": "ZK6dXFI584zg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from implementation import evaluator\n",
        "from implementation import evaluator_accelerate\n",
        "from implementation import code_manipulation\n",
        "from typing import Collection, Any, List, Tuple\n",
        "\n",
        "# 2. 实现SandBox接口\n",
        "class Sandbox(evaluator.Sandbox):\n",
        "    def __init__(self, verbose=False, numba_accelerate=True):\n",
        "        self._verbose = verbose\n",
        "        self._numba_accelerate = numba_accelerate\n",
        "\n",
        "    def run(\n",
        "            self,\n",
        "            program: str,\n",
        "            function_to_run: str,  # RZ: refers to the name of the function to run (e.g., 'evaluate')\n",
        "            function_to_evolve: str,  # RZ: accelerate the code by decorating @numba.jit() on function_to_evolve.\n",
        "            inputs: Any,  # refers to the dataset\n",
        "            test_input: str,  # refers to the current instance\n",
        "            timeout_seconds: int,\n",
        "            **kwargs  # RZ: add this\n",
        "    ) -> tuple[Any, bool]:\n",
        "        \"\"\"Returns `function_to_run(test_input)` and whether execution succeeded.\n",
        "\n",
        "        RZ: If the generated code (generated by LLM) is executed successfully,\n",
        "        the output of this function is the score of a given program.\n",
        "        RZ: PLEASE NOTE THAT this SandBox is only designed for bin-packing problem.\n",
        "        \"\"\"\n",
        "        dataset = inputs[test_input]\n",
        "        result_queue = multiprocessing.Queue()\n",
        "        process = multiprocessing.Process(\n",
        "            target=self._compile_and_run_function,\n",
        "            args=(program, function_to_run, function_to_evolve, dataset, self._numba_accelerate, result_queue)\n",
        "        )\n",
        "        process.start()\n",
        "        process.join(timeout=timeout_seconds)\n",
        "        if process.is_alive():\n",
        "            # if the process is not finished in time, we consider the program illegal\n",
        "            process.terminate()\n",
        "            process.join()\n",
        "            results = None, False\n",
        "        else:\n",
        "            if result_queue.qsize() != 0:\n",
        "                results = result_queue.get_nowait()\n",
        "            else:\n",
        "                results = None, False\n",
        "\n",
        "        if self._verbose:\n",
        "            print(f'================= Evaluated Program =================')\n",
        "            program_: code_manipulation.Program = code_manipulation.text_to_program(text=program)\n",
        "            func_to_evolve_: str = kwargs.get('func_to_evolve', 'priority')\n",
        "            function_: code_manipulation.Function = program_.get_function(func_to_evolve_)\n",
        "            function_: str = str(function_).strip('\\n')\n",
        "            print(f'{function_}')\n",
        "            print(f'-----------------------------------------------------')\n",
        "            print(f'Score: {str(results)}')\n",
        "            print(f'=====================================================')\n",
        "            print(f'\\n\\n')\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def _compile_and_run_function(self, program, function_to_run, function_to_evolve, dataset, numba_accelerate,\n",
        "                                  result_queue):\n",
        "        try:\n",
        "            if numba_accelerate:\n",
        "                program = evaluator_accelerate.add_numba_decorator(program, function_to_evolve=function_to_evolve)\n",
        "            all_globals_namespace = {}\n",
        "            exec(program, all_globals_namespace)\n",
        "            function_to_run = all_globals_namespace[function_to_run]\n",
        "            results = function_to_run(dataset)\n",
        "            if not isinstance(results, (int, float)):\n",
        "                result_queue.put((None, False))\n",
        "                return\n",
        "            result_queue.put((results, True))\n",
        "        except Exception:\n",
        "            result_queue.put((None, False))\n"
      ],
      "metadata": {
        "id": "jdPL3C9p_tU7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vbFoZueN_wqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 准备规范（specification）\n",
        "specification = r'''\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_valid_route_indices(vehicle_capacity: float, demands: np.ndarray, current_route: list, current_index: int) -> np.ndarray:\n",
        "    valid_indices = []\n",
        "    remaining_capacity = vehicle_capacity\n",
        "    for index in range(len(demands)):\n",
        "        if index not in current_route and demands[index] <= remaining_capacity:\n",
        "            valid_indices.append(index)\n",
        "    return np.array(valid_indices)\n",
        "\n",
        "\n",
        "def get_distance_between_nodes(node1_index, node2_index, node_locations):\n",
        "    return np.linalg.norm(node_locations[node1_index] - node_locations[node2_index])\n",
        "\n",
        "def vehicle_routing(vehicle_capacity: float, demands: np.ndarray, node_locations: np.ndarray) -> tuple[List[List[int]], np.ndarray]:\n",
        "    num_vehicles = 5  # 假设车辆数量\n",
        "    routes = [[] for _ in range(num_vehicles)]\n",
        "    vehicle_remaining_capacities = np.array([vehicle_capacity] * num_vehicles)\n",
        "    all_customers = set(range(len(demands)))\n",
        "    unvisited_customers = all_customers.copy()\n",
        "\n",
        "    for vehicle_index in range(num_vehicles):\n",
        "        current_route = []\n",
        "        current_capacity = vehicle_capacity\n",
        "        current_node = 0\n",
        "        while unvisited_customers:\n",
        "            valid_indices = get_valid_route_indices(current_capacity, demands, current_route, current_node)\n",
        "            if not valid_indices.size:\n",
        "                break\n",
        "            priorities = calculate_priority(current_capacity, demands[valid_indices], current_route, current_node)\n",
        "            best_node_index = valid_indices[np.argmax(priorities)]\n",
        "            current_route.append(best_node_index)\n",
        "            current_capacity -= demands[best_node_index]\n",
        "            unvisited_customers.remove(best_node_index)\n",
        "        routes[vehicle_index] = current_route\n",
        "        vehicle_remaining_capacities[vehicle_index] = current_capacity\n",
        "\n",
        "    return routes, vehicle_remaining_capacities\n",
        "\n",
        "\n",
        "@funsearch.run\n",
        "def evaluate(instances: dict) -> float:\n",
        "    total_vehicles_used = []\n",
        "    total_distance = []\n",
        "    for name in instances:\n",
        "        instance = instances[name]\n",
        "        vehicle_capacity = instance['vehicle_capacity']\n",
        "        demands = instance['demands']\n",
        "        node_locations = instance['node_locations']\n",
        "\n",
        "        routes, _ = vehicle_routing(vehicle_capacity, demands, node_locations)\n",
        "        used_vehicles = sum([1 for route in routes if route])\n",
        "        total_vehicles_used.append(used_vehicles)\n",
        "\n",
        "        distance = 0\n",
        "        for route in routes:\n",
        "            if route:\n",
        "                for i in range(len(route) - 1):\n",
        "                    distance += np.linalg.norm(node_locations[route[i]] - node_locations[route[i + 1]])\n",
        "        total_distance.append(distance)\n",
        "\n",
        "    score = - (0.5 * np.mean(total_vehicles_used) + 0.5 * np.mean(total_distance))\n",
        "    return score\n",
        "\n",
        "\n",
        "@funsearch.evolve\n",
        "def calculate_priority(vehicle_capacity: float, demands: np.ndarray, current_route: list, current_index: int,\n",
        "                       node_locations: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    计算节点的优先级。\n",
        "\n",
        "    :param vehicle_capacity: 车辆的剩余容量\n",
        "    :param demands: 客户需求数组\n",
        "    :param current_route: 当前车辆已经行驶的路线（节点索引列表）\n",
        "    :param current_index: 当前所在节点的索引\n",
        "    :param node_locations: 所有节点的位置数组\n",
        "    :return: 有效节点的优先级数组\n",
        "    \"\"\"\n",
        "    valid_indices = get_valid_route_indices(vehicle_capacity, demands, current_route, current_index)\n",
        "    priorities = []\n",
        "    for index in valid_indices:\n",
        "        try:\n",
        "            # 计算节点之间的实际距离\n",
        "            distance = get_distance_between_nodes(current_index, index, node_locations)\n",
        "            if distance == 0:\n",
        "                # 处理距离为0的异常情况，这里简单设置一个较大的优先级值\n",
        "                priority = float('inf')\n",
        "            else:\n",
        "                # 结合需求和距离计算优先级，这里增加一个权重因子来调整两者的影响程度\n",
        "                demand_weight = 0.6\n",
        "                distance_weight = 0.4\n",
        "                priority = demand_weight * demands[index] / distance + distance_weight / distance\n",
        "            priorities.append(priority)\n",
        "        except Exception as e:\n",
        "            print(f\"计算优先级时出现异常: {e}\")\n",
        "            priorities.append(0)\n",
        "    return np.array(priorities)\n",
        "'''"
      ],
      "metadata": {
        "id": "yNL-pTMCExsL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vrplib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTdWrVBFtwk",
        "outputId": "6d02e18d-0b3c-4254-a97c-288d7d1647ea"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vrplib\n",
            "  Downloading vrplib-1.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from vrplib) (2.0.2)\n",
            "Downloading vrplib-1.5.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: vrplib\n",
            "Successfully installed vrplib-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 准备数据集\n",
        "import vrplib\n",
        "import os\n",
        "\n",
        "setA_path = \"/content/drive/MyDrive/Vrp-Set-A/A\"\n",
        "dataset = {}\n",
        "dataset['A'] = {}\n",
        "\n",
        "for file in os.listdir(setA_path):\n",
        "    if file.endswith(\".vrp\"):\n",
        "        instances = vrplib.read_instance(os.path.join(setA_path, file))\n",
        "        dataset['A'][file[:-4]] = instances\n",
        "\n"
      ],
      "metadata": {
        "id": "N5kw4nz__yli"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import implementation.config\n",
        "from implementation import funsearch\n",
        "\n",
        "# 5. 启动FunSearch\n",
        "if __name__ == '__main__':\n",
        "    config = implementation.config.Config(samples_per_prompt=4)\n",
        "    class_config = implementation.config.ClassConfig(llm_class=LLMAPI, sandbox_class=Sandbox)\n",
        "    global_max_sample_num = 300\n",
        "    funsearch.main(\n",
        "        specification=specification,\n",
        "        inputs=dataset,\n",
        "        config=config,\n",
        "        max_sample_nums=global_max_sample_num,\n",
        "        class_config=class_config,\n",
        "        log_dir='../logs/funsearch_cvrp',\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E607SDh9_z4a",
        "outputId": "81723b47-02d6-4dea-be89-8f1ae9eeddcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================= Evaluated Function =================\n",
            "def calculate_priority(vehicle_capacity: float, demands: np.ndarray, current_route: list, current_index: int, node_locations: np.ndarray) -> np.ndarray:\n",
            "    \"\"\"\n",
            "    计算节点的优先级。\n",
            "\n",
            "    :param vehicle_capacity: 车辆的剩余容量\n",
            "    :param demands: 客户需求数组\n",
            "    :param current_route: 当前车辆已经行驶的路线（节点索引列表）\n",
            "    :param current_index: 当前所在节点的索引\n",
            "    :param node_locations: 所有节点的位置数组\n",
            "    :return: 有效节点的优先级数组\n",
            "    \"\"\"\n",
            "    valid_indices = get_valid_route_indices(vehicle_capacity, demands, current_route, current_index)\n",
            "    priorities = []\n",
            "    for index in valid_indices:\n",
            "        try:\n",
            "            # 计算节点之间的实际距离\n",
            "            distance = get_distance_between_nodes(current_index, index, node_locations)\n",
            "            if distance == 0:\n",
            "                # 处理距离为0的异常情况，这里简单设置一个较大的优先级值\n",
            "                priority = float('inf')\n",
            "            else:\n",
            "                # 结合需求和距离计算优先级，这里增加一个权重因子来调整两者的影响程度\n",
            "                demand_weight = 0.6\n",
            "                distance_weight = 0.4\n",
            "                priority = demand_weight * demands[index] / distance + distance_weight / distance\n",
            "            priorities.append(priority)\n",
            "        except Exception as e:\n",
            "            print(f\"计算优先级时出现异常: {e}\")\n",
            "            priorities.append(0)\n",
            "    return np.array(priorities)\n",
            "------------------------------------------------------\n",
            "Score        : None\n",
            "Sample time  : None\n",
            "Evaluate time: 0.25267982482910156\n",
            "Sample orders: None\n",
            "======================================================\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}